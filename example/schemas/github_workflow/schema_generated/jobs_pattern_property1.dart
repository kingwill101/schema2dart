// GENERATED CODE - DO NOT MODIFY BY HAND
// Source: example/schemas/github_workflow/schema.json
// Generated by json_schema2dart

import 'defaults.dart';
import 'env.dart';
import 'job_needs.dart';
import 'normal_job_concurrency.dart';
import 'normal_job_container.dart';
import 'normal_job_continue_on_error.dart';
import 'normal_job_environment.dart';
import 'normal_job_if.dart';
import 'normal_job_outputs.dart';
import 'normal_job_runs_on.dart';
import 'normal_job_services.dart';
import 'normal_job_strategy.dart';
import 'normal_job_timeout_minutes.dart';
import 'permissions.dart';
import 'reusable_workflow_call_job_concurrency.dart';
import 'reusable_workflow_call_job_if.dart';
import 'reusable_workflow_call_job_secrets.dart';
import 'reusable_workflow_call_job_strategy.dart';
import 'step.dart';
import 'validation_error.dart';

sealed class JobsPatternProperty1 {
  const JobsPatternProperty1();

  void validate({String pointer = '', ValidationContext? context});

  factory JobsPatternProperty1.fromJson(Map<String, dynamic> json) {
    final keys = json.keys.toSet();
    final sortedKeys = keys.toList()..sort();
    final requiredMatches =
        <JobsPatternProperty1 Function(Map<String, dynamic>)>[];
    final requiredMatchNames = <String>[];
    if (keys.contains('runs-on')) {
      requiredMatches.add(NormalJob.fromJson);
      requiredMatchNames.add('NormalJob');
    }
    if (keys.contains('uses')) {
      requiredMatches.add(ReusableWorkflowCallJob.fromJson);
      requiredMatchNames.add('ReusableWorkflowCallJob');
    }
    if (requiredMatches.length == 1) {
      return requiredMatches.single(json);
    }
    if (requiredMatches.length > 1) {
      throw ArgumentError(
        'Ambiguous JobsPatternProperty1 variant matched required-property heuristics: ${requiredMatchNames.join(', ')}',
      );
    }
    throw ArgumentError(
      'No JobsPatternProperty1 variant matched heuristics (keys: ${sortedKeys.join(', ')}).',
    );
  }

  Map<String, dynamic> toJson();
}

/// Each job must have an id to associate with the job. The key job_id is a string and its value is a map of the job's configuration data. You must replace <job_id> with a string that is unique to the jobs object. The <job_id> must start with a letter or _ and contain only alphanumeric characters, -, or _.
class NormalJob extends JobsPatternProperty1 {
  /// Concurrency ensures that only a single job or workflow using the same concurrency group will run at a time. A concurrency group can be any string or expression. The expression can use any context except for the secrets context.
  /// You can also specify concurrency at the workflow level.
  /// When a concurrent job or workflow is queued, if another job or workflow using the same concurrency group in the repository is in progress, the queued job or workflow will be pending. Any previously pending job or workflow in the concurrency group will be canceled. To also cancel any currently running job or workflow in the same concurrency group, specify cancel-in-progress: true.
  final NormalJobConcurrency? concurrency;

  /// A container to run any steps in a job that don't already specify a container. If you have steps that use both script and container actions, the container actions will run as sibling containers on the same network with the same volume mounts.
  /// If you do not set a container, all steps will run directly on the host specified by runs-on unless a step refers to an action configured to run in a container.
  final NormalJobContainer? container;

  /// Prevents a workflow run from failing when a job fails. Set to true to allow a workflow run to pass when this job fails.
  final NormalJobContinueOnError? continueOnError;

  /// A map of default settings that will apply to all steps in the job.
  final Defaults? defaults;

  /// A map of environment variables that are available to all steps in the job.
  final Env? env;

  /// The environment that the job references.
  final NormalJobEnvironment? environment;

  /// You can use the if conditional to prevent a job from running unless a condition is met. You can use any supported context and expression to create a conditional.
  /// Expressions in an if conditional do not require the ${{ }} syntax. For more information, see https://help.github.com/en/articles/contexts-and-expression-syntax-for-github-actions.
  /// Constraints: types: [boolean, number, string]
  final NormalJobIf? if_;

  /// The name of the job displayed on GitHub.
  final String? name;
  final JobNeeds? needs;

  /// A map of outputs for a job. Job outputs are available to all downstream jobs that depend on this job.
  /// Constraints: minProperties: 1
  final NormalJobOutputs? outputs;
  final Permissions? permissions;

  /// The type of machine to run the job on. The machine can be either a GitHub-hosted runner, or a self-hosted runner.
  final NormalJobRunsOn runsOn;

  /// Additional containers to host services for a job in a workflow. These are useful for creating databases or cache services like redis. The runner on the virtual machine will automatically create a network and manage the life cycle of the service containers.
  /// When you use a service container for a job or your step uses container actions, you don't need to set port information to access the service. Docker automatically exposes all ports between containers on the same network.
  /// When both the job and the action run in a container, you can directly reference the container by its hostname. The hostname is automatically mapped to the service name.
  /// When a step does not use a container action, you must access the service using localhost and bind the ports.
  final NormalJobServices? services;

  /// A job contains a sequence of tasks called steps. Steps can run commands, run setup tasks, or run an action in your repository, a public repository, or an action published in a Docker registry. Not all steps run actions, but all actions run as a step. Each step runs in its own process in the virtual environment and has access to the workspace and filesystem. Because steps run in their own process, changes to environment variables are not preserved between steps. GitHub provides built-in steps to set up and complete a job.
  /// Must contain either `uses` or `run`
  /// Constraints: minItems: 1
  final List<Step>? steps;

  /// A strategy creates a build matrix for your jobs. You can define different variations of an environment to run each job in.
  final NormalJobStrategy? strategy;

  /// The maximum number of minutes to let a workflow run before GitHub automatically cancels it. Default: 360
  ///
  /// Default: 360.
  final NormalJobTimeoutMinutes? timeoutMinutes;

  const NormalJob({
    this.concurrency,
    this.container,
    this.continueOnError,
    this.defaults,
    this.env,
    this.environment,
    this.if_,
    this.name,
    this.needs,
    this.outputs,
    this.permissions,
    required this.runsOn,
    this.services,
    this.steps,
    this.strategy,
    this.timeoutMinutes = const NormalJobTimeoutMinutesNum(360),
  }) : super();

  factory NormalJob.fromJson(Map<String, dynamic> json) {
    final remaining = Map<String, dynamic>.from(json);
    final concurrency = json['concurrency'] == null
        ? null
        : NormalJobConcurrency.fromJson(
            (json['concurrency'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('concurrency');
    final container = json['container'] == null
        ? null
        : NormalJobContainer.fromJson(
            (json['container'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('container');
    final continueOnError = json['continue-on-error'] == null
        ? null
        : NormalJobContinueOnError.fromJson(
            (json['continue-on-error'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('continue-on-error');
    final defaults = json['defaults'] == null
        ? null
        : Defaults.fromJson((json['defaults'] as Map).cast<String, dynamic>());
    remaining.remove('defaults');
    final env = json['env'] == null
        ? null
        : Env.fromJson((json['env'] as Map).cast<String, dynamic>());
    remaining.remove('env');
    final environment = json['environment'] == null
        ? null
        : NormalJobEnvironment.fromJson(
            (json['environment'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('environment');
    final if_ = json['if'] == null
        ? null
        : NormalJobIf.fromJson((json['if'] as Map).cast<String, dynamic>());
    remaining.remove('if');
    final name = json['name'] as String?;
    remaining.remove('name');
    final needs = json['needs'] == null
        ? null
        : JobNeeds.fromJson((json['needs'] as Map).cast<String, dynamic>());
    remaining.remove('needs');
    final outputs = json['outputs'] == null
        ? null
        : NormalJobOutputs.fromJson(
            (json['outputs'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('outputs');
    final permissions = json['permissions'] == null
        ? null
        : Permissions.fromJson(
            (json['permissions'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('permissions');
    final runsOn = NormalJobRunsOn.fromJson(
      (json['runs-on'] as Map).cast<String, dynamic>(),
    );
    remaining.remove('runs-on');
    final services = json['services'] == null
        ? null
        : NormalJobServices.fromJson(
            (json['services'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('services');
    final steps = json['steps'] == null
        ? null
        : (json['steps'] as List)
              .map((e) => Step.fromJson((e as Map).cast<String, dynamic>()))
              .toList();
    remaining.remove('steps');
    final strategy = json['strategy'] == null
        ? null
        : NormalJobStrategy.fromJson(
            (json['strategy'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('strategy');
    final timeoutMinutes =
        (json['timeout-minutes'] == null
            ? null
            : NormalJobTimeoutMinutes.fromJson(
                (json['timeout-minutes'] as Map).cast<String, dynamic>(),
              )) ??
        const NormalJobTimeoutMinutesNum(360);
    remaining.remove('timeout-minutes');
    var unmatched = Map<String, dynamic>.from(remaining);
    if (unmatched.isNotEmpty) {
      final unexpected = unmatched.keys.join(', ');
      throw ArgumentError('Unexpected additional properties: $unexpected');
    }
    return NormalJob(
      concurrency: concurrency,
      container: container,
      continueOnError: continueOnError,
      defaults: defaults,
      env: env,
      environment: environment,
      if_: if_,
      name: name,
      needs: needs,
      outputs: outputs,
      permissions: permissions,
      runsOn: runsOn,
      services: services,
      steps: steps,
      strategy: strategy,
      timeoutMinutes: timeoutMinutes,
    );
  }

  @override
  Map<String, dynamic> toJson() {
    final map = <String, dynamic>{};
    if (concurrency != null) map['concurrency'] = concurrency!.toJson();
    if (container != null) map['container'] = container!.toJson();
    if (continueOnError != null)
      map['continue-on-error'] = continueOnError!.toJson();
    if (defaults != null) map['defaults'] = defaults!.toJson();
    if (env != null) map['env'] = env!.toJson();
    if (environment != null) map['environment'] = environment!.toJson();
    if (if_ != null) map['if'] = if_!.toJson();
    if (name != null) map['name'] = name;
    if (needs != null) map['needs'] = needs!.toJson();
    if (outputs != null) map['outputs'] = outputs!.toJson();
    if (permissions != null) map['permissions'] = permissions!.toJson();
    map['runs-on'] = runsOn.toJson();
    if (services != null) map['services'] = services!.toJson();
    if (steps != null) map['steps'] = steps!.map((e) => e.toJson()).toList();
    if (strategy != null) map['strategy'] = strategy!.toJson();
    if (timeoutMinutes != null)
      map['timeout-minutes'] = timeoutMinutes!.toJson();
    return map;
  }

  @override
  void validate({String pointer = '', ValidationContext? context}) {
    final _ptr0 = appendJsonPointer(pointer, 'concurrency');
    final _value0 = concurrency;
    if (_value0 != null) {
      context?.markProperty(pointer, 'concurrency');
      final _jsonp0 = _value0.toJson();
      final _constraintp0c0_0 = context == null ? null : ValidationContext();
      var _constraintp0m0_0 = false;
      try {
        final context = _constraintp0c0_0;
        final _constraintp0v0_0 = _jsonp0 as String;
        _constraintp0m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp0c0_1 = context == null ? null : ValidationContext();
      var _constraintp0m0_1 = false;
      try {
        final context = _constraintp0c0_1;
        final _constraintp0v0_1 = Concurrency.fromJson(
          (_jsonp0 as Map).cast<String, dynamic>(),
        );
        _constraintp0v0_1.validate(pointer: _ptr0, context: context);
        _constraintp0m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp0matches0 = <bool>[
        _constraintp0m0_0,
        _constraintp0m0_1,
      ];
      final _constraintp0count0 = _constraintp0matches0
          .where((value) => value)
          .length;
      if (_constraintp0count0 != 1) {
        throwValidationError(
          _ptr0,
          'oneOf',
          'Expected exactly one subschema in #/definitions/normalJob/properties/concurrency/oneOf to validate.',
        );
      }
      if (context != null && _constraintp0m0_0 && _constraintp0c0_0 != null) {
        context.mergeFrom(_constraintp0c0_0!);
      }
      if (context != null && _constraintp0m0_1 && _constraintp0c0_1 != null) {
        context.mergeFrom(_constraintp0c0_1!);
      }
    }
    final _ptr1 = appendJsonPointer(pointer, 'container');
    final _value1 = container;
    if (_value1 != null) {
      context?.markProperty(pointer, 'container');
      final _jsonp1 = _value1.toJson();
      final _constraintp1c0_0 = context == null ? null : ValidationContext();
      var _constraintp1m0_0 = false;
      try {
        final context = _constraintp1c0_0;
        final _constraintp1v0_0 = _jsonp1 as String;
        _constraintp1m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp1c0_1 = context == null ? null : ValidationContext();
      var _constraintp1m0_1 = false;
      try {
        final context = _constraintp1c0_1;
        final _constraintp1v0_1 = Container.fromJson(
          (_jsonp1 as Map).cast<String, dynamic>(),
        );
        _constraintp1v0_1.validate(pointer: _ptr1, context: context);
        _constraintp1m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp1matches0 = <bool>[
        _constraintp1m0_0,
        _constraintp1m0_1,
      ];
      final _constraintp1count0 = _constraintp1matches0
          .where((value) => value)
          .length;
      if (_constraintp1count0 != 1) {
        throwValidationError(
          _ptr1,
          'oneOf',
          'Expected exactly one subschema in #/definitions/normalJob/properties/container/oneOf to validate.',
        );
      }
      if (context != null && _constraintp1m0_0 && _constraintp1c0_0 != null) {
        context.mergeFrom(_constraintp1c0_0!);
      }
      if (context != null && _constraintp1m0_1 && _constraintp1c0_1 != null) {
        context.mergeFrom(_constraintp1c0_1!);
      }
    }
    final _ptr2 = appendJsonPointer(pointer, 'continue-on-error');
    final _value2 = continueOnError;
    if (_value2 != null) {
      context?.markProperty(pointer, 'continue-on-error');
      final _jsonp2 = _value2.toJson();
      final _constraintp2c0_0 = context == null ? null : ValidationContext();
      var _constraintp2m0_0 = false;
      try {
        final context = _constraintp2c0_0;
        final _constraintp2v0_0 = _jsonp2 as bool;
        _constraintp2m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp2c0_1 = context == null ? null : ValidationContext();
      var _constraintp2m0_1 = false;
      try {
        final context = _constraintp2c0_1;
        final _constraintp2v0_1 = _jsonp2 as String;
        _constraintp2m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp2matches0 = <bool>[
        _constraintp2m0_0,
        _constraintp2m0_1,
      ];
      final _constraintp2count0 = _constraintp2matches0
          .where((value) => value)
          .length;
      if (_constraintp2count0 != 1) {
        throwValidationError(
          _ptr2,
          'oneOf',
          'Expected exactly one subschema in #/definitions/normalJob/properties/continue-on-error/oneOf to validate.',
        );
      }
      if (context != null && _constraintp2m0_0 && _constraintp2c0_0 != null) {
        context.mergeFrom(_constraintp2c0_0!);
      }
      if (context != null && _constraintp2m0_1 && _constraintp2c0_1 != null) {
        context.mergeFrom(_constraintp2c0_1!);
      }
    }
    final _ptr3 = appendJsonPointer(pointer, 'defaults');
    final _value3 = defaults;
    if (_value3 != null) {
      context?.markProperty(pointer, 'defaults');
      _value3.validate(pointer: _ptr3, context: context);
    }
    final _ptr4 = appendJsonPointer(pointer, 'env');
    final _value4 = env;
    if (_value4 != null) {
      context?.markProperty(pointer, 'env');
    }
    final _ptr5 = appendJsonPointer(pointer, 'environment');
    final _value5 = environment;
    if (_value5 != null) {
      context?.markProperty(pointer, 'environment');
      final _jsonp5 = _value5.toJson();
      final _constraintp5c0_0 = context == null ? null : ValidationContext();
      var _constraintp5m0_0 = false;
      try {
        final context = _constraintp5c0_0;
        final _constraintp5v0_0 = _jsonp5 as String;
        _constraintp5m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp5c0_1 = context == null ? null : ValidationContext();
      var _constraintp5m0_1 = false;
      try {
        final context = _constraintp5c0_1;
        final _constraintp5v0_1 = Environment.fromJson(
          (_jsonp5 as Map).cast<String, dynamic>(),
        );
        _constraintp5m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp5matches0 = <bool>[
        _constraintp5m0_0,
        _constraintp5m0_1,
      ];
      final _constraintp5count0 = _constraintp5matches0
          .where((value) => value)
          .length;
      if (_constraintp5count0 != 1) {
        throwValidationError(
          _ptr5,
          'oneOf',
          'Expected exactly one subschema in #/definitions/normalJob/properties/environment/oneOf to validate.',
        );
      }
      if (context != null && _constraintp5m0_0 && _constraintp5c0_0 != null) {
        context.mergeFrom(_constraintp5c0_0!);
      }
      if (context != null && _constraintp5m0_1 && _constraintp5c0_1 != null) {
        context.mergeFrom(_constraintp5c0_1!);
      }
    }
    final _ptr6 = appendJsonPointer(pointer, 'if');
    final _value6 = if_;
    if (_value6 != null) {
      context?.markProperty(pointer, 'if');
      if (!(_value6 is bool || _value6 is num || _value6 is String)) {
        throwValidationError(
          _ptr6,
          'type',
          'Expected value to match one of the allowed types [boolean, number, string].',
        );
      }
    }
    final _ptr7 = appendJsonPointer(pointer, 'name');
    final _value7 = name;
    if (_value7 != null) {
      context?.markProperty(pointer, 'name');
    }
    final _ptr8 = appendJsonPointer(pointer, 'needs');
    final _value8 = needs;
    if (_value8 != null) {
      context?.markProperty(pointer, 'needs');
    }
    final _ptr9 = appendJsonPointer(pointer, 'outputs');
    final _value9 = outputs;
    if (_value9 != null) {
      context?.markProperty(pointer, 'outputs');
      final _propertyCountp9 = _value9.toJson().length;
      if (_propertyCountp9 < 1) {
        throwValidationError(
          _ptr9,
          'minProperties',
          'Expected at least 1 properties but found ' +
              _propertyCountp9.toString() +
              '.',
        );
      }
    }
    final _ptr10 = appendJsonPointer(pointer, 'permissions');
    final _value10 = permissions;
    if (_value10 != null) {
      context?.markProperty(pointer, 'permissions');
    }
    final _ptr11 = appendJsonPointer(pointer, 'runs-on');
    final _value11 = runsOn;
    context?.markProperty(pointer, 'runs-on');
    final _jsonp11 = _value11.toJson();
    final _constraintp11c0_0 = context == null ? null : ValidationContext();
    var _constraintp11m0_0 = false;
    try {
      final context = _constraintp11c0_0;
      final _constraintp11v0_0 = _jsonp11 as String;
      _constraintp11m0_0 = true;
    } on ValidationError {
    } catch (_) {}
    final _constraintp11c0_1 = context == null ? null : ValidationContext();
    var _constraintp11m0_1 = false;
    try {
      final context = _constraintp11c0_1;
      final _constraintp11v0_1 = _jsonp11;
      final _jsonp11c0b1 = _constraintp11v0_1;
      final _constraintp11c0b1c0_0 = context == null
          ? null
          : ValidationContext();
      var _constraintp11c0b1m0_0 = false;
      try {
        final context = _constraintp11c0b1c0_0;
        final _constraintp11c0b1v0_0 = _jsonp11c0b1;
        _constraintp11c0b1m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp11c0b1matches0 = <bool>[_constraintp11c0b1m0_0];
      if (!_constraintp11c0b1matches0.any((value) => value)) {
        throwValidationError(
          _ptr11,
          'anyOf',
          'Expected at least one subschema in #/definitions/normalJob/properties/runs-on/anyOf/1/anyOf to validate.',
        );
      }
      if (context != null &&
          _constraintp11c0b1m0_0 &&
          _constraintp11c0b1c0_0 != null) {
        context.mergeFrom(_constraintp11c0b1c0_0!);
      }
      _constraintp11m0_1 = true;
    } on ValidationError {
    } catch (_) {}
    final _constraintp11c0_2 = context == null ? null : ValidationContext();
    var _constraintp11m0_2 = false;
    try {
      final context = _constraintp11c0_2;
      final _constraintp11v0_2 = NormalJobRunsOnObject.fromJson(
        (_jsonp11 as Map).cast<String, dynamic>(),
      );
      _constraintp11v0_2.validate(pointer: _ptr11, context: context);
      _constraintp11m0_2 = true;
    } on ValidationError {
    } catch (_) {}
    final _constraintp11c0_3 = context == null ? null : ValidationContext();
    var _constraintp11m0_3 = false;
    try {
      final context = _constraintp11c0_3;
      final _constraintp11v0_3 = _jsonp11 as String;
      _constraintp11m0_3 = true;
    } on ValidationError {
    } catch (_) {}
    final _constraintp11c0_4 = context == null ? null : ValidationContext();
    var _constraintp11m0_4 = false;
    try {
      final context = _constraintp11c0_4;
      final _constraintp11v0_4 = _jsonp11 as String;
      _constraintp11m0_4 = true;
    } on ValidationError {
    } catch (_) {}
    final _constraintp11matches0 = <bool>[
      _constraintp11m0_0,
      _constraintp11m0_1,
      _constraintp11m0_2,
      _constraintp11m0_3,
      _constraintp11m0_4,
    ];
    if (!_constraintp11matches0.any((value) => value)) {
      throwValidationError(
        _ptr11,
        'anyOf',
        'Expected at least one subschema in #/definitions/normalJob/properties/runs-on/anyOf to validate.',
      );
    }
    if (context != null && _constraintp11m0_0 && _constraintp11c0_0 != null) {
      context.mergeFrom(_constraintp11c0_0!);
    }
    if (context != null && _constraintp11m0_1 && _constraintp11c0_1 != null) {
      context.mergeFrom(_constraintp11c0_1!);
    }
    if (context != null && _constraintp11m0_2 && _constraintp11c0_2 != null) {
      context.mergeFrom(_constraintp11c0_2!);
    }
    if (context != null && _constraintp11m0_3 && _constraintp11c0_3 != null) {
      context.mergeFrom(_constraintp11c0_3!);
    }
    if (context != null && _constraintp11m0_4 && _constraintp11c0_4 != null) {
      context.mergeFrom(_constraintp11c0_4!);
    }
    final _ptr12 = appendJsonPointer(pointer, 'services');
    final _value12 = services;
    if (_value12 != null) {
      context?.markProperty(pointer, 'services');
      _value12.validate(pointer: _ptr12, context: context);
    }
    final _ptr13 = appendJsonPointer(pointer, 'steps');
    final _value13 = steps;
    if (_value13 != null) {
      context?.markProperty(pointer, 'steps');
      if (_value13.length < 1) {
        throwValidationError(
          _ptr13,
          'minItems',
          'Expected at least 1 items but found ' +
              _value13.length.toString() +
              '.',
        );
      }
      final _lenp13 = _value13.length;
      final _evaluatedp13 = List<bool>.filled(_lenp13, false);
      for (var i = 0; i < _lenp13; i++) {
        final itemPointer = appendJsonPointer(_ptr13, i.toString());
        final item = _value13[i];
        item.validate(pointer: itemPointer, context: context);
        _evaluatedp13[i] = true;
        context?.markItem(_ptr13, i);
      }
    }
    final _ptr14 = appendJsonPointer(pointer, 'strategy');
    final _value14 = strategy;
    if (_value14 != null) {
      context?.markProperty(pointer, 'strategy');
      _value14.validate(pointer: _ptr14, context: context);
    }
    final _ptr15 = appendJsonPointer(pointer, 'timeout-minutes');
    final _value15 = timeoutMinutes;
    context?.annotate(
      _ptr15,
      'default',
      360,
      schemaPointer: '#/definitions/normalJob/properties/timeout-minutes',
    );
    if (_value15 != null) {
      context?.markProperty(pointer, 'timeout-minutes');
      final _jsonp15 = _value15.toJson();
      final _constraintp15c0_0 = context == null ? null : ValidationContext();
      var _constraintp15m0_0 = false;
      try {
        final context = _constraintp15c0_0;
        final _constraintp15v0_0 = _jsonp15 as double;
        _constraintp15m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp15c0_1 = context == null ? null : ValidationContext();
      var _constraintp15m0_1 = false;
      try {
        final context = _constraintp15c0_1;
        final _constraintp15v0_1 = _jsonp15 as String;
        _constraintp15m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp15matches0 = <bool>[
        _constraintp15m0_0,
        _constraintp15m0_1,
      ];
      final _constraintp15count0 = _constraintp15matches0
          .where((value) => value)
          .length;
      if (_constraintp15count0 != 1) {
        throwValidationError(
          _ptr15,
          'oneOf',
          'Expected exactly one subschema in #/definitions/normalJob/properties/timeout-minutes/oneOf to validate.',
        );
      }
      if (context != null && _constraintp15m0_0 && _constraintp15c0_0 != null) {
        context.mergeFrom(_constraintp15c0_0!);
      }
      if (context != null && _constraintp15m0_1 && _constraintp15c0_1 != null) {
        context.mergeFrom(_constraintp15c0_1!);
      }
    }
  }
}

/// Each job must have an id to associate with the job. The key job_id is a string and its value is a map of the job's configuration data. You must replace <job_id> with a string that is unique to the jobs object. The <job_id> must start with a letter or _ and contain only alphanumeric characters, -, or _.
class ReusableWorkflowCallJob extends JobsPatternProperty1 {
  /// Concurrency ensures that only a single job or workflow using the same concurrency group will run at a time. A concurrency group can be any string or expression. The expression can use any context except for the secrets context.
  /// You can also specify concurrency at the workflow level.
  /// When a concurrent job or workflow is queued, if another job or workflow using the same concurrency group in the repository is in progress, the queued job or workflow will be pending. Any previously pending job or workflow in the concurrency group will be canceled. To also cancel any currently running job or workflow in the same concurrency group, specify cancel-in-progress: true.
  final ReusableWorkflowCallJobConcurrency? concurrency;

  /// You can use the if conditional to prevent a job from running unless a condition is met. You can use any supported context and expression to create a conditional.
  /// Expressions in an if conditional do not require the ${{ }} syntax. For more information, see https://help.github.com/en/articles/contexts-and-expression-syntax-for-github-actions.
  /// Constraints: types: [boolean, number, string]
  final ReusableWorkflowCallJobIf? if_;

  /// The name of the job displayed on GitHub.
  final String? name;
  final JobNeeds? needs;
  final Permissions? permissions;

  /// When a job is used to call a reusable workflow, you can use 'secrets' to provide a map of secrets that are passed to the called workflow. Any secrets that you pass must match the names defined in the called workflow.
  final ReusableWorkflowCallJobSecrets? secrets;

  /// A strategy creates a build matrix for your jobs. You can define different variations of an environment to run each job in.
  final ReusableWorkflowCallJobStrategy? strategy;

  /// The location and version of a reusable workflow file to run as a job, of the form './{path/to}/{localfile}.yml' or '{owner}/{repo}/{path}/{filename}@{ref}'. {ref} can be a SHA, a release tag, or a branch name. Using the commit SHA is the safest for stability and security.
  /// Constraints: pattern: ^(.+\/)+(.+)\.(ya?ml)(@.+)?$
  final String uses;

  /// A map of inputs that are passed to the called workflow. Any inputs that you pass must match the input specifications defined in the called workflow. Unlike 'jobs.<job_id>.steps[*].with', the inputs you pass with 'jobs.<job_id>.with' are not be available as environment variables in the called workflow. Instead, you can reference the inputs by using the inputs context.
  final Env? with_;

  const ReusableWorkflowCallJob({
    this.concurrency,
    this.if_,
    this.name,
    this.needs,
    this.permissions,
    this.secrets,
    this.strategy,
    required this.uses,
    this.with_,
  }) : super();

  factory ReusableWorkflowCallJob.fromJson(Map<String, dynamic> json) {
    final remaining = Map<String, dynamic>.from(json);
    final concurrency = json['concurrency'] == null
        ? null
        : ReusableWorkflowCallJobConcurrency.fromJson(
            (json['concurrency'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('concurrency');
    final if_ = json['if'] == null
        ? null
        : ReusableWorkflowCallJobIf.fromJson(
            (json['if'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('if');
    final name = json['name'] as String?;
    remaining.remove('name');
    final needs = json['needs'] == null
        ? null
        : JobNeeds.fromJson((json['needs'] as Map).cast<String, dynamic>());
    remaining.remove('needs');
    final permissions = json['permissions'] == null
        ? null
        : Permissions.fromJson(
            (json['permissions'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('permissions');
    final secrets = json['secrets'] == null
        ? null
        : ReusableWorkflowCallJobSecrets.fromJson(
            (json['secrets'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('secrets');
    final strategy = json['strategy'] == null
        ? null
        : ReusableWorkflowCallJobStrategy.fromJson(
            (json['strategy'] as Map).cast<String, dynamic>(),
          );
    remaining.remove('strategy');
    final uses = json['uses'] as String;
    remaining.remove('uses');
    final with_ = json['with'] == null
        ? null
        : Env.fromJson((json['with'] as Map).cast<String, dynamic>());
    remaining.remove('with');
    var unmatched = Map<String, dynamic>.from(remaining);
    if (unmatched.isNotEmpty) {
      final unexpected = unmatched.keys.join(', ');
      throw ArgumentError('Unexpected additional properties: $unexpected');
    }
    return ReusableWorkflowCallJob(
      concurrency: concurrency,
      if_: if_,
      name: name,
      needs: needs,
      permissions: permissions,
      secrets: secrets,
      strategy: strategy,
      uses: uses,
      with_: with_,
    );
  }

  @override
  Map<String, dynamic> toJson() {
    final map = <String, dynamic>{};
    if (concurrency != null) map['concurrency'] = concurrency!.toJson();
    if (if_ != null) map['if'] = if_!.toJson();
    if (name != null) map['name'] = name;
    if (needs != null) map['needs'] = needs!.toJson();
    if (permissions != null) map['permissions'] = permissions!.toJson();
    if (secrets != null) map['secrets'] = secrets!.toJson();
    if (strategy != null) map['strategy'] = strategy!.toJson();
    map['uses'] = uses;
    if (with_ != null) map['with'] = with_!.toJson();
    return map;
  }

  @override
  void validate({String pointer = '', ValidationContext? context}) {
    final _ptr0 = appendJsonPointer(pointer, 'concurrency');
    final _value0 = concurrency;
    if (_value0 != null) {
      context?.markProperty(pointer, 'concurrency');
      final _jsonp0 = _value0.toJson();
      final _constraintp0c0_0 = context == null ? null : ValidationContext();
      var _constraintp0m0_0 = false;
      try {
        final context = _constraintp0c0_0;
        final _constraintp0v0_0 = _jsonp0 as String;
        _constraintp0m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp0c0_1 = context == null ? null : ValidationContext();
      var _constraintp0m0_1 = false;
      try {
        final context = _constraintp0c0_1;
        final _constraintp0v0_1 = Concurrency.fromJson(
          (_jsonp0 as Map).cast<String, dynamic>(),
        );
        _constraintp0v0_1.validate(pointer: _ptr0, context: context);
        _constraintp0m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp0matches0 = <bool>[
        _constraintp0m0_0,
        _constraintp0m0_1,
      ];
      final _constraintp0count0 = _constraintp0matches0
          .where((value) => value)
          .length;
      if (_constraintp0count0 != 1) {
        throwValidationError(
          _ptr0,
          'oneOf',
          'Expected exactly one subschema in #/definitions/reusableWorkflowCallJob/properties/concurrency/oneOf to validate.',
        );
      }
      if (context != null && _constraintp0m0_0 && _constraintp0c0_0 != null) {
        context.mergeFrom(_constraintp0c0_0!);
      }
      if (context != null && _constraintp0m0_1 && _constraintp0c0_1 != null) {
        context.mergeFrom(_constraintp0c0_1!);
      }
    }
    final _ptr1 = appendJsonPointer(pointer, 'if');
    final _value1 = if_;
    if (_value1 != null) {
      context?.markProperty(pointer, 'if');
      if (!(_value1 is bool || _value1 is num || _value1 is String)) {
        throwValidationError(
          _ptr1,
          'type',
          'Expected value to match one of the allowed types [boolean, number, string].',
        );
      }
    }
    final _ptr2 = appendJsonPointer(pointer, 'name');
    final _value2 = name;
    if (_value2 != null) {
      context?.markProperty(pointer, 'name');
    }
    final _ptr3 = appendJsonPointer(pointer, 'needs');
    final _value3 = needs;
    if (_value3 != null) {
      context?.markProperty(pointer, 'needs');
    }
    final _ptr4 = appendJsonPointer(pointer, 'permissions');
    final _value4 = permissions;
    if (_value4 != null) {
      context?.markProperty(pointer, 'permissions');
    }
    final _ptr5 = appendJsonPointer(pointer, 'secrets');
    final _value5 = secrets;
    if (_value5 != null) {
      context?.markProperty(pointer, 'secrets');
      final _jsonp5 = _value5.toJson();
      final _constraintp5c0_0 = context == null ? null : ValidationContext();
      var _constraintp5m0_0 = false;
      try {
        final context = _constraintp5c0_0;
        final _constraintp5v0_0 = Env.fromJson(
          (_jsonp5 as Map).cast<String, dynamic>(),
        );
        _constraintp5m0_0 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp5c0_1 = context == null ? null : ValidationContext();
      var _constraintp5m0_1 = false;
      try {
        final context = _constraintp5c0_1;
        final _constraintp5v0_1 =
            ReusableWorkflowCallJobSecretsStringJson.fromJson(
              _jsonp5 as String,
            );
        _constraintp5m0_1 = true;
      } on ValidationError {
      } catch (_) {}
      final _constraintp5matches0 = <bool>[
        _constraintp5m0_0,
        _constraintp5m0_1,
      ];
      final _constraintp5count0 = _constraintp5matches0
          .where((value) => value)
          .length;
      if (_constraintp5count0 != 1) {
        throwValidationError(
          _ptr5,
          'oneOf',
          'Expected exactly one subschema in #/definitions/reusableWorkflowCallJob/properties/secrets/oneOf to validate.',
        );
      }
      if (context != null && _constraintp5m0_0 && _constraintp5c0_0 != null) {
        context.mergeFrom(_constraintp5c0_0!);
      }
      if (context != null && _constraintp5m0_1 && _constraintp5c0_1 != null) {
        context.mergeFrom(_constraintp5c0_1!);
      }
    }
    final _ptr6 = appendJsonPointer(pointer, 'strategy');
    final _value6 = strategy;
    if (_value6 != null) {
      context?.markProperty(pointer, 'strategy');
      _value6.validate(pointer: _ptr6, context: context);
    }
    final _ptr7 = appendJsonPointer(pointer, 'uses');
    final _value7 = uses;
    context?.markProperty(pointer, 'uses');
    final _patternp7 = RegExp('^(.+\\/)+(.+)\\.(ya?ml)(@.+)?\$');
    if (!_patternp7.hasMatch(_value7)) {
      throwValidationError(
        _ptr7,
        'pattern',
        'Expected value to match pattern ^(.+\\/)+(.+)\\.(ya?ml)(@.+)?\$ but found ' +
            _value7 +
            '.',
      );
    }
    final _ptr8 = appendJsonPointer(pointer, 'with');
    final _value8 = with_;
    if (_value8 != null) {
      context?.markProperty(pointer, 'with');
    }
  }
}
